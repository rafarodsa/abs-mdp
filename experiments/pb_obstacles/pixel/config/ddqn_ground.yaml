# environment.yaml
experiment_cwd: exp_results/pb_obstacles/pixel/mdps
experiment_name: pinball_rssm_large_pixel_4__model.latentdim_6__seed_0
env:
  absmdp: ${experiment_cwd}/${experiment_name}/cont_mdp.pt
  sample_abstract_transition: true
  absgroundmdp: false
  render: false
  init_thresh: 0.5
  use_ground_init: false
  reward_scale: 0. #0.00016666666666666666
  gamma: 0.9997
  goal: 0

agent:
  load: null
  final_exploration_steps: 500000
  final_epsilon: 0.1
  eval_epsilon: 0.001
  replay_start_size: 10000
  replay_buffer_size: 500000
  target_update_interval: 10000
  steps: 1250000
  update_interval: 5
  num_step_return: 1
  lr: 1e-5
  eval_random_agent: false
  gamma: ${env.gamma}
  normalize_obs: false

q_func: 
  n_actions: 4
  ground:
    type: doubling_residual
    in_width: 50
    in_height: 50
    color_channels: 1
    depth: 24
    cnn_blocks: 2
    min_resolution: 4
    mlp_layers: [256, ]
    outdim: 4
    mlp_activation: silu
    cnn_activation: silu
  abstract:
    type: 'mlp'
    hidden_dims: [128, 128]
    activation: relu
    output_dim: ${q_func.n_actions}

experiment:
  seed: 31
  gpu: 0
  demo: false
  eval_interval: 10000
  eval_n_runs: 10
  log_level: 20
  checkpoint_frequency: null
  max_episode_len: 100
  log_tensorboard: false
  outdir: planning_ddqn
  finetune: false

finetuning:
  final_exploration_steps: 30000
  final_epsilon: 0.1
  eval_epsilon: 0.001
  target_update_interval: 1000
  steps: 250000
  lr: 0.0005